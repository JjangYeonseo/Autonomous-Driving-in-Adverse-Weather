# ğŸš— Robust Object Detection in Adverse Weather Conditions

This project aims to develop a multimodal deep learning model for object detection that remains **robust under adverse weather conditions**, including fog, rain, snow, and night-time scenarios.

By fusing **camera (image)** and **LiDAR (point cloud)** data, the model can maintain high perception accuracy even in low-visibility environmentsâ€”making it suitable for real-world autonomous driving applications.

## ğŸ¯ Project Objectives

- Build a robust object detection model for various weather and lighting conditions
- Fuse image (RGB) and LiDAR (BEV) data to enhance detection reliability
- Use polygon-based annotation files for both image and LiDAR
- Align with real-world sensor configurations and environmental diversity

## ğŸ§° Requirements & Environment Setup

### 1. Python Version
- Python 3.9 (recommended via Anaconda)

### 2. Package Installation

Install all dependencies using:

```bash
pip install -r requirements.txt
```

Key packages:
- `torch`, `torchvision` (CUDA 11.8 compatible)
- `open3d` (for processing `.pcd` files)
- `opencv-python`, `numpy`, `pandas`, `matplotlib`, `scikit-learn`, `pyyaml`, `seaborn`, `tqdm`

### 3. CUDA Support

- Tested with CUDA driver **12.8.1**
- PyTorch uses **CUDA 11.8 build**, which runs smoothly on higher versions

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Main configuration file
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.py               # Custom PyTorch Dataset (Image + LiDAR)
â”‚   â””â”€â”€ preprocessing/           # Auto-generated after preprocessing
â”‚       â”œâ”€â”€ cleaned_data.csv     # Valid data samples
â”‚       â””â”€â”€ classes.txt          # List of all object classes
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ fusion_model.py          # Fusion model (Image + LiDAR)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_data.py       # Cleans dataset, extracts classes
â”‚   â”œâ”€â”€ train.py                 # Trains the fusion model
â”‚   â”œâ”€â”€ test.py                  # Runs inference on test set
â”‚   â”œâ”€â”€ evaluate.py              # Calculates accuracy and confusion matrix
â”‚   â””â”€â”€ run_pipeline.py          # Automates training â†’ testing â†’ evaluation â†’ visualization
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ lidar_utils.py           # Converts .pcd â†’ BEV images
â”‚   â””â”€â”€ visualization.py         # Saves image predictions as visual output
â”‚
â”œâ”€â”€ checkpoints/                 # Model weights saved during training
â”œâ”€â”€ outputs/                     # Predictions, confusion matrix, and visualizations
â””â”€â”€ requirements.txt             # Python dependencies
```

## ğŸš€ Pipeline: Step-by-Step Guide

### Step 1: Preprocess the dataset
```bash
python scripts/preprocess_data.py
```
- Filters out invalid labels
- Creates `cleaned_data.csv` and `classes.txt`
- You must **edit `num_classes` in `config.yaml`** based on the number of lines in `classes.txt`

### Step 2: Train the model
```bash
python scripts/train.py --config configs/config.yaml
```
- Checkpoints are saved to `checkpoints/epoch_*.pt`

### Step 3: Test the model
```bash
python scripts/test.py --config configs/config.yaml
```
- Predictions are saved to `outputs/test_results.csv`

### Step 4: Evaluate performance
```bash
python scripts/evaluate.py
```
- Shows classification report and saves `confusion_matrix.png`

### Step 5: Visualize predictions
```python
from utils.visualization import visualize_predictions
import yaml
config = yaml.safe_load(open("configs/config.yaml"))
visualize_predictions(config, sample_count=10)
```
- Saves annotated images to `outputs/vis/`

### One Command for Everything (recommended!)
```bash
python scripts/run_pipeline.py
```
Runs the full pipeline: **Training â†’ Testing â†’ Evaluation â†’ Visualization**

## ğŸ’¡ Benefits

- Maintains high object detection performance in harsh weather
- Combines image + LiDAR input to compensate for low visibility
- Robust to noise, direction, and environmental variety
- Can be extended to real-time deployment or 3D perception models

## ğŸ”® Expected Outcomes

- Test accuracy target: **80%+**
- Class-wise performance analysis via confusion matrix
- Visual confirmation of predicted vs ground truth labels

## ğŸ“Œ Notes

- `data/preprocessing/` and `outputs/` folders are created automatically
- It is recommended to add these folders to `.gitignore` if pushing to GitHub:

```
outputs/
data/preprocessing/
checkpoints/
```
## cf) Source Data Structure

The data is organized into two main categories:
1. **Labeling Data**: JSON files containing object and segmentation information for each image in different weather conditions.
2. **Raw Data**: Images in JPG format and LiDAR data in PCD format.

## cf) Training Data Structure

```
traindata/
â”œâ”€â”€ labellingdata/
â”‚   â”œâ”€â”€ TL_Hazy/
â”‚   â”‚   â””â”€â”€ Hazy/
â”‚   â”‚       â”œâ”€â”€ Day/
â”‚   â”‚       â”‚   â”œâ”€â”€ Back/
â”‚   â”‚       â”‚   â”œâ”€â”€ Front/
â”‚   â”‚       â”‚   â”œâ”€â”€ IR/
â”‚   â”‚       â”‚   â”œâ”€â”€ Left/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Center/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Left/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Right/
â”‚   â”‚       â”‚   â””â”€â”€ Right/
â”‚   â”‚       â””â”€â”€ Night/
â”‚   â”œâ”€â”€ TL_Normal/
â”‚   â”‚   â””â”€â”€ Normal/
â”‚   â”‚       â”œâ”€â”€ Day/
â”‚   â”‚       â”‚   â”œâ”€â”€ Back/
â”‚   â”‚       â”‚   â”œâ”€â”€ Front/
â”‚   â”‚       â”‚   â”œâ”€â”€ IR/
â”‚   â”‚       â”‚   â”œâ”€â”€ Left/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Center/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Left/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Right/
â”‚   â”‚       â”‚   â””â”€â”€ Right/
â”‚   â”‚       â””â”€â”€ Night/
â”‚   â”œâ”€â”€ TL_Rainy/
â”‚   â”‚   â””â”€â”€ Rainy/
â”‚   â”‚       â”œâ”€â”€ Day/
â”‚   â”‚       â”‚   â”œâ”€â”€ Back/
â”‚   â”‚       â”‚   â”œâ”€â”€ Front/
â”‚   â”‚       â”‚   â”œâ”€â”€ IR/
â”‚   â”‚       â”‚   â”œâ”€â”€ Left/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Center/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Left/
â”‚   â”‚       â”‚   â”œâ”€â”€ Lidar_Right/
â”‚   â”‚       â”‚   â””â”€â”€ Right/
â”‚   â”‚       â””â”€â”€ Night/
â”‚   â””â”€â”€ TL_Snowy/
â”‚       â””â”€â”€ Snowy/
â”‚           â”œâ”€â”€ Day/
â”‚           â”‚   â”œâ”€â”€ Back/
â”‚           â”‚   â”œâ”€â”€ Front/
â”‚           â”‚   â”œâ”€â”€ IR/
â”‚           â”‚   â”œâ”€â”€ Left/
â”‚           â”‚   â”œâ”€â”€ Lidar_Center/
â”‚           â”‚   â”œâ”€â”€ Lidar_Left/
â”‚           â”‚   â”œâ”€â”€ Lidar_Right/
â”‚           â”‚   â””â”€â”€ Right/
â”‚           â””â”€â”€ Night/
â””â”€â”€ sourcedata/
    â”œâ”€â”€ TS_Hazy/
    â”‚   â””â”€â”€ Hazy/
    â”‚       â”œâ”€â”€ Day/
    â”‚       â”‚   â”œâ”€â”€ Back/
    â”‚       â”‚   â”œâ”€â”€ Front/
    â”‚       â”‚   â”œâ”€â”€ IR/
    â”‚       â”‚   â”œâ”€â”€ Left/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Center/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Left/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Right/
    â”‚       â”‚   â””â”€â”€ Right/
    â”‚       â””â”€â”€ Night/
    â”œâ”€â”€ TS_Normal/
    â”‚   â””â”€â”€ Normal/
    â”‚       â”œâ”€â”€ Day/
    â”‚       â”‚   â”œâ”€â”€ Back/
    â”‚       â”‚   â”œâ”€â”€ Front/
    â”‚       â”‚   â”œâ”€â”€ IR/
    â”‚       â”‚   â”œâ”€â”€ Left/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Center/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Left/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Right/
    â”‚       â”‚   â””â”€â”€ Right/
    â”‚       â””â”€â”€ Night/
    â”‚           â”œâ”€â”€ Lidar_Center/
    â”‚           â””â”€â”€ Lidar_Left/
    â”œâ”€â”€ TS_Rainy/
    â”‚   â””â”€â”€ Rainy/
    â”‚       â”œâ”€â”€ Day/
    â”‚       â”‚   â”œâ”€â”€ Back/
    â”‚       â”‚   â”œâ”€â”€ Front/
    â”‚       â”‚   â”œâ”€â”€ IR/
    â”‚       â”‚   â”œâ”€â”€ Left/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Center/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Left/
    â”‚       â”‚   â”œâ”€â”€ Lidar_Right/
    â”‚       â”‚   â””â”€â”€ Right/
    â”‚       â””â”€â”€ Night/
    â”‚           â”œâ”€â”€ Back/
    â”‚           â”œâ”€â”€ Front/
    â”‚           â”œâ”€â”€ IR/
    â”‚           â”œâ”€â”€ Left/
    â”‚           â”œâ”€â”€ Lidar_Center/
    â”‚           â”œâ”€â”€ Lidar_Left/
    â”‚           â”œâ”€â”€ Lidar_Right/
    â”‚           â””â”€â”€ Right/
    â””â”€â”€ TS_Snowy/
        â””â”€â”€ Snowy/
            â”œâ”€â”€ Day/
            â”‚   â”œâ”€â”€ Back/
            â”‚   â”œâ”€â”€ Front/
            â”‚   â”œâ”€â”€ IR/
            â”‚   â”œâ”€â”€ Left/
            â”‚   â”œâ”€â”€ Lidar_Center/
            â”‚   â”œâ”€â”€ Lidar_Left/
            â”‚   â”œâ”€â”€ Lidar_Right/
            â”‚   â””â”€â”€ Right/
            â””â”€â”€ Night/
```
